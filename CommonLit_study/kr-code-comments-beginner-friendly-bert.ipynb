{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"ê°œì¸ ê³µë¶€ ëª©ì ìœ¼ë¡œ BERTëª¨ë¸ì„ ì´ìš©í•œ Baseline ì½”ë“œì— ì£¼ì„ì„ í•œ ì¤„ì”© ë‹¬ì•„ë´¤ìŠµë‹ˆë‹¤.\n\nreference : https://www.kaggle.com/code/suraj520/beginner-friendly-bert (ì´ì½”ë“œ ì›ë³¸)\nreference : https://www.kaggle.com/code/kimseunghee/kr-code-comments-beginner-friendly-bert (í•œê¸€ ì£¼ì„ ë‹¬ì•„ì£¼ì‹ ë¶„)\n\nFor my own learning, I've provided Korean comments on each line of the baseline code","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#5D73F2; color:#19180F; font-size:40px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\"> Beginner friendly approach </div>\n<div style=\"background-color:#D5D9F2; color:#19180F; font-size:15px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\">\n<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nğŸ“Œ\nBERT based approach. Know more about the architecture of BERT via <a href=\"https://www.kaggle.com/code/suraj520/bert-know-fit-infer\"> kernel </a>   </div>\n</div>","metadata":{}},{"cell_type":"markdown","source":"\n<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nğŸ“Œ\nImporting modules\n    </div>","metadata":{}},{"cell_type":"code","source":"# ëª¨ë“ˆ ì„í¬íŠ¸\nimport torch # Pytorch ë”¥ëŸ¬ë‹ì„ ìœ„í•œ ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë ˆì„ ì›Œí¬, í…ì„œ ì—°ì‚°, ì‹ ê²½ë§ ëª¨ë¸, ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ë“±ì„ ì œê³µ\nimport torch.nn as nn # torchì—ì„œ ì œê³µí•˜ëŠ” ì‹±ê²½ë§ ëª¨ë“ˆ, ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ì‹ ê²½ë§ ëª¨ë¸ì„ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤.\nfrom transformers import BertModel, BertTokenizer # transformer ë¼ì…ëŸ¬ë¦¬ì—ì„œ BERT, Tokenizer ëª¨ë¸ì„ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤Œ\nimport pandas as pd # ë°ì´í„° ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬, í…Œì´ë¸” í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ë° ìœ ìš©\nfrom sklearn.model_selection import train_test_split # ë°ì´í„°ì…‹ì„ í•™ìŠµ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:32:27.046642Z","iopub.execute_input":"2023-10-08T11:32:27.047038Z","iopub.status.idle":"2023-10-08T11:32:43.135383Z","shell.execute_reply.started":"2023-10-08T11:32:27.047003Z","shell.execute_reply":"2023-10-08T11:32:43.134205Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nğŸ“Œ\nLoading the data    </div>","metadata":{}},{"cell_type":"code","source":"# ë°ì´í„° ë¡œë“œ\n# í•´ë‹¹ ê²½ë¡œì— ìˆëŠ” ë°ì´í„°ì…‹ì„ ì½ì–´ì™€ train_data, test_dataì— ì €ì¥\ntrain_data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\ntest_data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:32:56.693668Z","iopub.execute_input":"2023-10-08T11:32:56.694119Z","iopub.status.idle":"2023-10-08T11:32:56.809200Z","shell.execute_reply.started":"2023-10-08T11:32:56.694085Z","shell.execute_reply":"2023-10-08T11:32:56.807762Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"display(train_data.head())\ndisplay(test_data.head())","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:33:00.450283Z","iopub.execute_input":"2023-10-08T11:33:00.452677Z","iopub.status.idle":"2023-10-08T11:33:00.487406Z","shell.execute_reply.started":"2023-10-08T11:33:00.452608Z","shell.execute_reply":"2023-10-08T11:33:00.486084Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"     student_id prompt_id                                               text  \\\n0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n\n    content   wording  \n0  0.205683  0.380538  \n1 -0.548304  0.506755  \n2  3.128928  4.231226  \n3 -0.210614 -0.471415  \n4  3.272894  3.219757  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000e8c3c7ddb</td>\n      <td>814d6b</td>\n      <td>The third wave was an experimentto see how peo...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0020ae56ffbf</td>\n      <td>ebad26</td>\n      <td>They would rub it up with soda to make the sme...</td>\n      <td>-0.548304</td>\n      <td>0.506755</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004e978e639e</td>\n      <td>3b9047</td>\n      <td>In Egypt, there were many occupations and soci...</td>\n      <td>3.128928</td>\n      <td>4.231226</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>005ab0199905</td>\n      <td>3b9047</td>\n      <td>The highest class was Pharaohs these people we...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0070c9e7af47</td>\n      <td>814d6b</td>\n      <td>The Third Wave developed  rapidly because the ...</td>\n      <td>3.272894</td>\n      <td>3.219757</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     student_id prompt_id            text\n0  000000ffffff    abc123  Example text 1\n1  111111eeeeee    def789  Example text 2\n2  222222cccccc    abc123  Example text 3\n3  333333dddddd    def789  Example text 4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>abc123</td>\n      <td>Example text 1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>111111eeeeee</td>\n      <td>def789</td>\n      <td>Example text 2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>222222cccccc</td>\n      <td>abc123</td>\n      <td>Example text 3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>def789</td>\n      <td>Example text 4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"\n<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nğŸ“Œ\nPreprocessing the data (ë°ì´í„° ì „ì²˜ë¦¬)    </div>","metadata":{}},{"cell_type":"code","source":"'''\nBertTokenizerëŠ” Hugging Faceì˜ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì œê³µí•˜ëŠ” BERT ëª¨ë¸ì„ ìœ„í•œ í† í¬ë‚˜ì´ì €ë¡œ, í…ìŠ¤íŠ¸ ëª¨ë¸ì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í˜•íƒœì˜ í† í°ìœ¼ë¡œ ë³€í™˜í•œë‹¤.\nfrom_pretrained('ëª¨ë¸ ì´ë¦„ ë˜ëŠ” ê²½ë¡œ') : íŠ¹ì • ëª¨ë¸ì„ ì¸ìë¡œ ì œê³µí•˜ë©´ í•´ë‹¹ ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì € config ë° vocabì„ ë¡œë“œí•  ìˆ˜ ìˆë‹¤.\n'''\ntokenizer = BertTokenizer.from_pretrained('/kaggle/input/hugging-face-models-safe-tensors/bert-base-uncased')\n\n\n\n'''\n# 'BertTokenizer' ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ BERT ëª¨ë¸ì— ì…ë ¥ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰\n\n- batch_encode_plusëŠ” ì—¬ëŸ¬ê°œì˜ í…ìŠ¤íŠ¸ ë¬¸ì¥ì„ í•œ ë²ˆì— ì¸ì½”ë”© í•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤.\n- tolist()ëŠ” pandasì˜ DataFrameì´ ì œê³µí•˜ëŠ” ë©”ì„œë“œë¡œ, í•´ë‹¹(df['text'] column) ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•œë‹¤.\n- tolist()ë¥¼ í•˜ëŠ” ì´ìœ  : batch_encode_plusëŠ” ì…ë ¥ìœ¼ë¡œ Python ë¦¬ìŠ¤íŠ¸, íŠœí”Œ ë˜ëŠ” ë‹¤ë¥¸ ì‹œí€€ìŠ¤ í˜•íƒœì˜ ë°ì´í„°ë¥¼ ë°›ì„ ìˆ˜ ìˆê¸°ë•Œë¬¸ì—\n- turncation = True : í…ìŠ¤íŠ¸ì˜ ê¸¸ì´ê°€ ëª¨ë¸ì˜ max_lengthë¥¼ ì´ˆê³¼í•  ê²½ìš°, í…ìŠ¤íŠ¸ë¥¼ ì˜ë¼ë‚¸ë‹¤. (ëª¨ë¸ì˜ ìµœëŒ€ ê¸¸ì´ : 512)\n- padding = True : ì¸ì½”ë”©ëœ í…ìŠ¤íŠ¸ê°€ ë™ì¼í•œ ê¸¸ì´ë¥¼ ê°–ë„ë¡ íŒ¨ë”©ì„ ì¶”ê°€.\n'''\ntrain_encodings = tokenizer.batch_encode_plus(\n    train_data['text'].tolist(),\n    truncation = True,\n    padding = True\n)\n\n\n# test dataì—ë„ ë™ì¼í•˜ê²Œ ì ìš©\ntest_encodings = tokenizer.batch_encode_plus(\n    test_data['text'].tolist(),\n    truncation = True,\n    padding = True\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:33:50.938363Z","iopub.execute_input":"2023-10-08T11:33:50.938814Z","iopub.status.idle":"2023-10-08T11:34:03.172065Z","shell.execute_reply.started":"2023-10-08T11:33:50.938782Z","shell.execute_reply":"2023-10-08T11:34:03.170642Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# type : transformers.tokenization_utils_base.BatchEncoding\n# input_ids, token_type_ids, attention_mask\ntest_encodings['token_type_ids']","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:41:57.971037Z","iopub.execute_input":"2023-10-08T11:41:57.971405Z","iopub.status.idle":"2023-10-08T11:41:57.978904Z","shell.execute_reply.started":"2023-10-08T11:41:57.971376Z","shell.execute_reply":"2023-10-08T11:41:57.977544Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]"},"metadata":{}}]},{"cell_type":"code","source":"'''\n{'input_ids': [[101, 2742, 3793, 1015, 102], [101, 2742, 3793, 1016, 102], [101, 2742, 3793, 1017, 102], [101, 2742, 3793, 1018, 102]], \n'token_type_ids': [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], \n'attention_mask': [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n# Tensor ê°œë… ì°¸ê³ ë§í¬ : https://rekt77.tistory.com/102\n# TensorëŠ” ë°°ì—´ì˜ ì§‘í•©, matrixì˜ ì§‘í•©ì´ Tensorê¸° ë•Œë¬¸ì— 3ì°¨ì›ë¶€í„° ì‹œì‘í•œë‹¤.\n\n'''\n- torch.utils.data.TensorDataset : í…ì„œë“¤ì˜ ë°ì´í„°ì…‹ì„ ë§Œë“ ë‹¤. ì—¬ëŸ¬ê°œì˜ í…ì„œ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë°ì´í„°ì…‹ìœ¼ë¡œ ë¬¶ì„ ë•Œ ì‚¬ìš©\n- ìœ„ì—ì„œ tokenizer.batch_encode_plus()ë¥¼ ì‚¬ìš©í•´ì„œ ì¸ì½”ë”©í•œ ê²°ê³¼ì—ì„œ 'input_ids'ë¥¼ ê°€ì ¸ì˜¨ë‹¤.\n- 'input_ids'ëŠ” í† í°í™”ëœ í…ìŠ¤íŠ¸ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìˆ«ì IDì˜ ë¦¬ìŠ¤íŠ¸ì´ë‹¤.\n- 'attention_mask' ëŠ” 0,1 ë¡œ êµ¬ì„±ë˜ì–´ìˆëŠ”ë°, ì‹¤ì œ í† í°ì€ 1, íŒ¨ë”© í† í°ì€ 0ì˜ ê°’ì„ ê°€ì§„ë‹¤.\n- .tolist() : torch.tensorê°€ pandasì˜ Seriesê°ì²´ë¥¼ ì§ì ‘ ì²˜ë¦¬í•  ìˆ˜ ì—†ì–´ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ ('content, wording')\n   torch.tensor() numpy ë°°ì—´, python ë¦¬ìŠ¤íŠ¸ ë“±ê³¼ ê°™ì€ ë°ì´í„° í˜•ì‹ì„ ë°›ì„ ìˆ˜ ìˆë‹¤.\n'''\n\ntrain_dataset = torch.utils.data.TensorDataset(\n    torch.tensor(train_encodings['input_ids']),   # BERT ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë  'input_ids'ë¥¼ Torch í…ì„œë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬\n    torch.tensor(train_encodings['attention_mask']), # BERT ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë  'attention_mask'ë¥¼ Torch í…ì„œë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬\n    torch.tensor(train_data['content'].tolist()), # ì´ í…ì„œëŠ” í•™ìŠµê³¼ì •ì—ì„œ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì„ ë¹„êµí•˜ëŠ”ë° ì‚¬ìš©ë  ì˜ˆì •\n    torch.tensor(train_data['wording'].tolist())\n)\n\n\n# test dataì—ë„ ë™ì¼í•˜ê²Œ ì ìš©\ntest_dataset = torch.utils.data.TensorDataset(\n    torch.tensor(test_encodings['input_ids']),\n    torch.tensor(test_encodings['attention_mask'])\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:45:18.704753Z","iopub.execute_input":"2023-10-08T11:45:18.705250Z","iopub.status.idle":"2023-10-08T11:45:20.205020Z","shell.execute_reply.started":"2023-10-08T11:45:18.705215Z","shell.execute_reply":"2023-10-08T11:45:20.204053Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# train_dataset ë‚´ìš© í™•ì¸\n\nprint(\"ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ Inputs ids\", train_dataset[0][0]) # í† í°í™”ëœ í…ìŠ¤íŠ¸ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìˆ«ì IDì˜ ë¦¬ìŠ¤íŠ¸, ê°’ì´ 0ìœ¼ë¡œ ë“¤ì–´ê°€ìˆëŠ”ê±°ëŠ” íŒ¨ë”©ìœ¼ë¡œ ì±„ì›Œì§\nprint(\"ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ attention Mask\", train_dataset[0][1]) # 0, 1ë¡œ ì´ë£¨ì–´ì¡Œê³ , ì‹¤ì œ í† í°ì€ 1, íŒ¨ë”© í† í°ì€ 0ì˜ ê°’ì„ ê°€ì§\nprint(\"ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ 'content'\", train_dataset[0][2]) # content ì—´ì˜ ì²«ë²ˆì§¸ í–‰ì— ìˆëŠ” ë°ì´í„° ê°’\nprint(\"ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ 'wording'\", train_dataset[0][3]) # wording ì—´ì˜ ì²«ë²ˆì§¸ í–‰ì— ìˆëŠ” ë°ì´í„° ê°’\n\nprint(\"ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ Inputs ids shape \", train_dataset[0][0].shape) \nprint(\"ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ attention Mask shape\", train_dataset[0][1].shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-08T11:45:51.323729Z","iopub.execute_input":"2023-10-08T11:45:51.324202Z","iopub.status.idle":"2023-10-08T11:45:51.436514Z","shell.execute_reply.started":"2023-10-08T11:45:51.324160Z","shell.execute_reply":"2023-10-08T11:45:51.435555Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ Inputs ids tensor([  101,  1996,  2353,  4400,  2001,  2019,  7551,  3406,  2156,  2129,\n         2111, 14831,  2000,  1037,  2047,  2028,  3003,  2231,  1012,  2009,\n         4227,  6217,  2004,  2111,  2359,  2000,  3046,  2047,  2477,  1012,\n         1996,  2493,  3582,  2505,  2008,  2003,  2056,  1998,  2707,  3810,\n         2006,  2169, 14573,  2121,  2000,  5114,  3020,  2373,  1012,  2027,\n         2018,  2000,  2644,  1996,  4654,  4842, 13665,  2004,  2205,  2116,\n         2111,  2288,  2000,  7490,  2007,  2009, 25734,  2206,  2045,  3003,\n          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])\nì²« ë²ˆì§¸ ë¬¸ì¥ì˜ attention Mask tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])\nì²« ë²ˆì§¸ ë¬¸ì¥ì˜ 'content' tensor(0.2057)\nì²« ë²ˆì§¸ ë¬¸ì¥ì˜ 'wording' tensor(0.3805)\nì²« ë²ˆì§¸ ë¬¸ì¥ì˜ Inputs ids shape  torch.Size([512])\nì²« ë²ˆì§¸ ë¬¸ì¥ì˜ attention Mask shape torch.Size([512])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nğŸ“Œ\nDefining the BERT model (BERT)ëª¨ë¸ ì •ì˜í•˜ê¸°   </div>","metadata":{}},{"cell_type":"code","source":"## nn.Module ëª¨ë“  ëª¨ë¸ì˜ ê·¼ê°„ì´ ë˜ëŠ” ê¸°ë³¸ í´ë˜ìŠ¤\n\n'''\nnn.Moduleì€ PyTorchì˜ ì‹ ê²½ë§ ë ˆì´ì–´ ë° ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ” ë° í•„ìš”í•œ í•µì‹¬ êµ¬ì„± ìš”ì†Œë¥¼ ì œê³µ \nnn ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” Neural Networkì˜ ëª¨ë“  ê²ƒì„ í¬ê´„í•˜ëŠ” ëª¨ë“  ì‹ ê²½ë§ ëª¨ë¸ì˜ Base Classì´ë‹¤. ì¦‰ ëª¨ë“  ì‹ ê²½ë§ ëª¨ë¸ì€ nn.Moduleì˜ subclassë¼ê³  í•  ìˆ˜ ìˆë‹¤.\n\n\n1. ëª¨ë“ˆí™” (Modularity): nn.Moduleì„ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì„ ì—¬ëŸ¬ ê°œì˜ ëª¨ë“ˆë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ ëª¨ë¸ì„ ëª¨ë“ˆë¡œ êµ¬ì„±í•˜ë©´ ëª¨ë“ˆ ê°„ì˜ ì¬ì‚¬ìš©ì„±ì´ ë†’ì•„ì§€ê³ \n   ë³µì¡í•œ ëª¨ë¸ì„ ì‰½ê²Œ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´, ìˆœí™˜ ë ˆì´ì–´, ì„ í˜• ë ˆì´ì–´ ë“±ì˜ ì„œë¡œ ë‹¤ë¥¸ ëª¨ë“ˆì„ ì¡°í•©í•˜ì—¬ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n2. ë§¤ê°œë³€ìˆ˜ ê´€ë¦¬: nn.Moduleì€ ëª¨ë¸ ë‚´ì˜ ëª¨ë“  ë§¤ê°œë³€ìˆ˜ (ê°€ì¤‘ì¹˜ ë° í¸í–¥)ë¥¼ ì¶”ì í•˜ê³  ì‰½ê²Œ ê´€ë¦¬í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. \n   ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, ë§¤ê°œë³€ìˆ˜ ì—…ë°ì´íŠ¸, ì €ì¥ ë° ë¡œë“œ ë“±ì„ í¸ë¦¬í•˜ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n3. ìˆœì „íŒŒ ì •ì˜: ëª¨ë¸ì˜ ìˆœì „íŒŒ ì—°ì‚°ì„ forward ë©”ì„œë“œì— ì •ì˜í•©ë‹ˆë‹¤. ì´ ë©”ì„œë“œëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ë°›ì•„ ëª¨ë¸ì„ í†µê³¼ì‹œì¼œ ì¶œë ¥ì„ ë°˜í™˜í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. \n   forward ë©”ì„œë“œë¥¼ ì •ì˜í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì´ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n4. .to() ë©”ì„œë“œ: nn.Module í´ë˜ìŠ¤ë¥¼ ìƒì†í•œ ëª¨ë“  ëª¨ë“ˆì€ .to(device) ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ CPU ë˜ëŠ” GPUë¡œ ì´ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n    ì´ë¥¼ í†µí•´ í•˜ë“œì›¨ì–´ ê°€ì†ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµ ë° ì¶”ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n5. ëª¨ë¸ ì €ì¥ ë° ë¡œë“œ: nn.Module í´ë˜ìŠ¤ëŠ” ëª¨ë¸ì˜ ìƒíƒœë¥¼ ì €ì¥í•˜ê³  ë¡œë“œí•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ë©”ì„œë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í•™ìŠµëœ ëª¨ë¸ì„ ì €ì¥í•˜ê³  ë‚˜ì¤‘ì— ì¬ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\n__init__() : ëª¨ë¸ì„ ë§Œë“¤ë•Œ ê·¸ êµ¬ì¡°ë¥¼ ì •ì˜ í•´ì¤˜ì•¼ í•˜ëŠ”ë° __init__()ì„ í†µí•´ ë§Œë“œëŠ”ê²Œ ê·œì¹™\nforward() : ëª¨ë¸ì´ ì–´ë–»ê²Œ forward propagationì„ í• ì§€ ì •ì˜í•˜ëŠ” ë¶€ë¶„, ë˜‘ê°™ì´ ë ˆì´ì–´ë¥¼ ë§Œë“¤ë”ë¼ê³  ì–´ë–»ê²Œ ì—°ì‚°ì„ í•  ê²ƒì¸ì§€ì— ë”°ë¼ ì™„ì „íˆ ë‹¤ë¥¸ ëª¨ë¸ì´ ëœë‹¤.\n\nìœ„ ë‘ê°€ì§€ë§Œ ìˆì–´ë„ ëª¨ë¸ì€ ì •ì˜ë˜ê³  forward/backwardë¥¼ ë¬¸ì œ ì—†ì´ ìˆ˜í–‰í•˜ê³  í•™ìŠµ í•  ìˆ˜ ìˆìŒ.\n\n\n'''\n\n\n\nclass BERTModel(nn.Module): # Pytorchì˜ nn.Module í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ì„œ ì‚¬ìš©í•œë‹¤.\n    def __init__(self): # ëª¨ë¸ì˜ êµ¬ì¡°ì™€ ë™ì‘ì„ ì •ì˜í•˜ëŠ” ìƒì„±ìë¥¼ ì •ì˜. ì´ëŠ” íŒŒì´ì¬ì—ì„œ ê°ì²´ê°€ ê°–ëŠ” ì†ì„±ê°’ì„ ì´ˆê¸°í™”í•˜ëŠ” ì—­í• ë¡œ, ê°ì²´ê°€ ìƒì„±ë  ë•Œ ìë™ìœ¼í˜¸ í˜¸ì¶œ\n        super(BERTModel, self).__init__() # ë¶€ëª¨ í´ë˜ìŠ¤ì¸ nn.Moduleì˜ ì´ˆê¸°í™” ë©”ì„œë“œë¥¼ í˜¸ì¶œ\n        \n        # pretrain ëœ BERT ëª¨ë¸ ë¡œë“œ bert-base-uncased\"ëŠ” ì†Œë¬¸ìë§Œ ê³ ë ¤í•˜ëŠ” BERTì˜ ê¸°ë³¸ ë²„ì „\n        # 12ê°œì˜ transformer ê³„ì¸µìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê° í† í°ì— ëŒ€í•´ 768ì°¨ì›ì˜ ë²¡í„°ë¥¼ ì¶œë ¥í•œë‹¤.\n        self.bert = BertModel.from_pretrained('/kaggle/input/hugging-face-models-safe-tensors/bert-base-uncased') \n        \n        \n        \n        # dropout ê³„ì¸µìœ¼ë¡œ ì‹ ê²½ë§ í•™ìŠµ ì¤‘ ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ëª©ì ìœ¼ë¡œ ì‚¬ìš©, dropout ê³„ì¸µì€ í•™ìŠµ ê³¼ì •ì—ì„œ ì¼ë¶€ ë‰´ëŸ°ì„ ì„ì˜ë¡œ ë¹„í™œì„±í™” \n        # (ì¦‰,ê·¸ ì¶œë ¥ì„ 0ìœ¼ë¡œ ì„¤ì •)í•˜ì—¬ íŠ¹ì • ë‰´ëŸ°ì— ë„ˆë¬´ ì˜ì¡´í•˜ì§€ ì•Šë„ë¡ ì„¤ì •\n        self.dropout = nn.Dropout(0.1) # overfitting ë°©ì§€ë¥¼ ìœ„í•œ ë“œë¡­ì•„ì›ƒ\n        \n        \n        # self.linear1, self.linear2 ì´ë“¤ì€ ì„ í˜•(ë˜ëŠ” ì™„ì „ ì—°ê²°)ê³„ì¸µ ì„ í˜• ê³„ì¸µì€ ì…ë ¥ ë²¡í„°ì™€ ê°€ì¤‘ì¹˜ í–‰ë ¬ ì‚¬ì´ì˜ ì„ í˜• ë³€í™˜(linear transformation)ì„ ìˆ˜í–‰.\n        # BERTê°€ ìƒì„±í•œ ì„ë² ë”© ë²¡í„°ë“¤ì— ëŒ€í•´ ì¶”ê°€ì ì¸ ë³€í™˜ì„ ìˆ˜í–‰í•œë‹¤.\n        # nn.Linear(768, 256)ê³¼ ê°™ì€ í¬ê¸° ì„¤ì •ì€ BERT ëª¨ë¸ì˜ ì¶œë ¥ ì°¨ì›ê³¼ ê´€ë ¨ ,bert-base-uncased ëª¨ë¸ì€ ê° ì…ë ¥ í† í°ì— ëŒ€í•´\n        # 768ì°¨ì› ë²¡í„°ë¥¼ ì¶œë ¥í•˜ë¯€ë¡œ ì²« ë²ˆì§¸ ì„ í˜• ê³„ì¸µì€ ì…ë ¥ ì°¨ì›ë„ 768ë¡œ ì„¤ì • ë˜ì–´ ìˆì–´ì•¼ í•¨.\n        # 256ì€ ì²«ë²ˆì§¸ ì„ í˜• ê³„ì¸µ(self.linear1)ì—ì„œ ìƒì„±í•  ìƒˆë¡œìš´ feature vectorì˜ í¬ê¸°ë¥¼ ì •í•˜ëŠ” ê°’\n        self.linear1 = nn.Linear(768, 256)# ì²« ë²ˆì§¸ ì„ í˜• ë ˆì´ì–´ ì…ë ¥ í¬ê¸°ëŠ” 768(BERT ëª¨ë¸ì˜ íˆë“  ë ˆì´ì–´ í¬ê¸°), ì¶œë ¥ í¬ê¸°ëŠ” 256\n        \n        \n        \n        # nn.Linear(256, 2)ì—ì„œ 2ëŠ” ìµœì¢… ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ë©° ë¬¸ì œ ì¢…ë¥˜ë‚˜ ë°ì´í„° ì…‹ì´ ë”°ë¼ ë‹¬ë¼ì§„ë‹¤. \n        # ì˜ˆë¥¼ ë“¤ì–´ binary classification ë¬¸ì œì¸ ê²½ìš° '2'ê°€ ëœë‹¤.\n        self.linear2 = nn.Linear(256, 2) # ë‘ ë²ˆì§¸ ì„ í˜• ë ˆì´ì–´. ì…ë ¥í¬ê¸°ëŠ” 256 ì¶œë ¥í¬ê¸°ëŠ” 2\n        \n        '''\n        ë ˆì´ì–´ í¬ê¸°ê°€ ëª¨ë¸ì˜ ì–´ë–¤ ì˜í–¥ì„ ë¼ì¹˜ë‚˜?\n        ë ˆì´ì–´ì˜ í¬ê¸°ëŠ” ì‹ ê²½ë§ ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ ë³µì¡ë„ì— ì¤‘ìš”í•œ ì˜í–¥ì„ ì¤€ë‹¤.\n        \n        ëª¨ë¸ì˜ ìš©ëŸ‰(Capacity) : ë ˆì´ì–´ì˜ í¬ê¸°ê°€ í´ìˆ˜ë¡, ëª¨ë¸ì€ ë” ë§ì€ ì •ë³´ë¥¼ í•™ìŠµí•˜ê³  ë³µì¡í•œ íŒ¨í„´ì„ ì¸ì‹í•  ìˆ˜ ìˆê³  ì´ëŠ” ëª¨ë¸ì˜ \"ìš©ëŸ‰\"ì„ ì¦ê°€ ì‹œí‚¨ë‹¤.\n        ë°˜ë©´ì— ë„ˆë¬´ ì‘ì€ ë ˆì´ì–´ í¬ê¸°ëŠ” ëª¨ë¸ì´ ì¶©ë¶„íˆ í•™ìŠµí•˜ì§€ ëª»í•˜ê²Œ ë§Œë“¤ ìˆ˜ ìˆë‹¤(underfitting) ë„ˆë¬´ í¬ë©´(overfitting)\n        \n        ê³„ì‚° ë¹„ìš©(Computational Cost) : ë” í° ë ˆì´ì–´ë¥¼ ê°€ì§„ ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ê³„ì‚° ë¹„ìš©ì´ ë” ë§ì´ ë“¤ê³  ì´ëŠ” í›ˆë ¨ ì‹œê°„ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€ë¡œ ì´ì–´ì§„ë‹¤.\n        \n        ëª¨ë¸ì˜ êµ¬ì¡°(Model Archi'tecture) : ì¼ë¶€ ê²½ìš°ì—ì„œ, ì…ë ¥ ë°ì´í„°ë‚˜ ë¬¸ì œ ìì²´ê°€ íŠ¹ì • ì°¨ì›ì˜ ì¶œë ¥ì„ ìš”êµ¬ í•  ìˆ˜ ìˆë‹¤. ( e.g. ë¶„ë¥˜ ë¬¸ì œì—ì„œ í´ë˜ìŠ¤ ìˆ˜ )\n        ì´ëŸ° ê²½ìš°  í•´ë‹¹ ì°¨ì›ìœ¼ë¡œ ì¶œë ¥í•˜ëŠ” ê³„ì¸µ(layer)ë¥¼ ë§ˆì§€ë§‰ì— ì¶”ê°€\n\n        '''\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    def forward(self, input_ids, attention_mask):\n        \n        # input_idsì™€ attention_maskë¥¼ BERT ëª¨ë¸ì— ì „ë‹¬í•˜ê³  BERT ëª¨ë¸ì€ ì…ë ¥ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì˜ ì¸ì½”ë”© í•˜ì—¬ ì¶œë ¥í•˜ê³  ê·¸ ê²°ê³¼ë¥¼ outputsì— ë‹´ëŠ”ë‹¤.\n        outputs = self.bert(input_ids= input_ids, attention_mask= attention_mask)  \n        \n        \n        pooled_output = outputs.pooler_output # pooled_outputì€ ë¬¸ì¥ì— ëŒ€í•œ ê³ ìˆ˜ì¤€ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” ë²¡í„°ë¡œ, ì¼ë°˜ì ìœ¼ë¡œ ë¬¸ì¥ ë¶„ë¥˜ ì‘ì—…ì— ì‚¬ìš©\n        pooled_output = self.dropout(pooled_output) # Dropout ê³„ì¸µì„ í†µê³¼í•˜ì—¬  overfittingì„ ë°©ì§€í•˜ë„ë¡ í•œë‹¤.\n        '''\n        pooler_outputì´ë€? BERTì˜ ë§ˆì§€ë§‰ Transformer ê³„ì¸µì—ì„œ [CLS] í† í°ì˜ ì¶œë ¥ì„ ê°€ì ¸ì™€ì„œ\n        ì¶”ê°€ì ì¸ Dense ë ˆì´ì–´ë¥¼ í†µê³¼ì‹œí‚¨ ê²°ê³¼ì´ë‹¤. \n        ì´ CLS í† í°ì˜ ì„ë² ë”©ì€ ì „ì²´ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ë¬¸ë§¥ì  ìš”ì•½ìœ¼ë¡œ ìƒ¤ìš©ëœë‹¤.\n        ë”°ë¼ì„œ ì´ CLS í† í°ì˜ ì„ë² ë”©(pooler_output)ì„ ì´ìš©í•´ì„œ ì¶”ê°€ ì‘ì—…ì„ í•œë‹¤.\n        '''\n        \n        output = self.linear1(pooled_output) # ì²« ë²ˆì§¸ ì„ í˜• ë ˆì´ì–´ í†µê³¼\n        output = nn.ReLU()(output) # activation functionì¸ ReLU ì ìš©í•˜ì—¬ ë¹„ì„ í˜•ì„±(non-linearity)ì„ ì¶”ê°€\n        output = self.linear2(output) # ë‘ ë²ˆì§¸ ì„ í˜• ë ˆì´ì–´ í†µê³¼ì‹œí‚¤ê³  ê²°ê³¼ ë°˜í™˜\n        return output\n    \n    \"\"\"\n    ì´ëŸ° ì‹ìœ¼ë¡œ êµ¬ì„±ëœ ì´ìœ ëŠ”, ì‚¬ì „í•™ìŠµëœ BERT ëª¨ë¸ì´ ì´ë¯¸ ë³µì¡í•œ ìì—°ì–´ ì²˜ë¦¬ ì‘ì—…ì— í•„ìš”í•œ ëŒ€ë¶€ë¶„ì˜ ì •ë³´ë¥¼ ì¸ì½”ë”©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. \n    ê·¸ëŸ¬ë‚˜ ìš°ë¦¬ê°€ í•´ê²°í•˜ë ¤ëŠ” êµ¬ì²´ì ì¸ ë¬¸ì œ(ì˜ˆ: ë¶„ë¥˜ ë¬¸ì œ ë“±)ì— ë”°ë¼ ì¶”ê°€ì ì¸ ë³€í™˜ ë° í•™ìŠµì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n    ë”°ë¼ì„œ ì´ ì½”ë“œì—ì„œëŠ” BERT ëª¨ë¸ì˜ ì¶œë ¥ì¸ 'pooler_output' ë²¡í„°ë¥¼ ì¶”ê°€ì ì¸ ì„ í˜• ê³„ì¸µë“¤(self.linear1, self.linear2)ë¡œ ë³´ë‚´ì–´ \n    ì›í•˜ëŠ” í˜•íƒœ(ì—¬ê¸°ì„œëŠ” 2ê°œ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.)ë¡œ ë³€í™˜í•˜ë„ë¡ í•˜ì˜€ìŠµë‹ˆë‹¤.\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-10-07T04:37:24.269235Z","iopub.execute_input":"2023-10-07T04:37:24.269876Z","iopub.status.idle":"2023-10-07T04:37:24.281015Z","shell.execute_reply.started":"2023-10-07T04:37:24.269845Z","shell.execute_reply":"2023-10-07T04:37:24.280104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nğŸ“Œ\nTraining the BERT model    </div>","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # CUDAê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ deviceëŠ” 'cuda'ë¡œ ì„¤ì •ë˜ê³ , ì•„ë‹ˆë©´ 'cpu'ë¡œ ëœë‹¤.\n\n# ì•ì—ì„œ ì •ì˜í•œ BERTModel í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ì¸ modelì„ ìƒì„±í•˜ê³  to(device)ë¥¼ ì•ì„œ ì •ì˜í•œ ì¥ì¹˜(device)ë¡œ ë³´ë‚¸ í›„ ê³„ì‚° ì§„í–‰\nmodel = BERTModel().to(device) \n\n\n'''\nì‹ ê²½ë§ í•™ìŠµì˜ ëª©í‘œëŠ” ì£¼ì–´ì§„ ë°ì´í„°ì— ëŒ€í•´ ì˜ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— ì´ë¥¼ ìœ„í•´ì„œëŠ” ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°(ê°€ì¤‘ì¹˜ì™€ í¸í–¥ ë“±) ì ì ˆí•˜ê²Œ ì¡°ì •í•´ì•¼ í•œë‹¤. \nì´ íŒŒë¼ë¯¸í„° ì¡°ì • ê³¼ì •ì´ ìµœì í™”(Optimization)ì´ë‹¤.  ìµœì í™” ê³¼ì •ì—ì„œëŠ” ì†ì‹¤ í•¨ìˆ˜(Loss Function)ë¥¼ ìµœì†Œí™” í•˜ëŠ” íŒŒë¼ë¯¸í„° ê°’ì„ ì°¾ëŠ”ë‹¤.\nì†ì‹¤ í•¨ìˆ˜ ê°’ì€ ëª¨ë¸ì˜ ì˜ˆì¸¡ê³¼ ì‹¤ì œ ê°’ ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ë‚˜íƒ€ë‚´ë¯€ë¡œ ì´ ê°’ì„ ìµœì†Œí™” í•œë‹¤ëŠ” ê²ƒì€ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ìµœëŒ€í™” í•œë‹¤ëŠ” ê²ƒê³¼ ë™ì¼.\nì˜µí‹°ë§ˆì´ì €(Optimizer)ëŠ” ì´ëŸ¬í•œ ìµœì í™” ê³¼ì •ì„ ìˆ˜í–‰í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ê³  ì—¬ê¸°ì„œ ì‚¬ìš©ëœ AdamW ì˜µí‹°ë§ˆì´ì € ê°™ì€ ê²½ìš° , ê° íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ì†ì‹¤ í•¨ìˆ˜ì˜ \nê·¸ë˜ë””ì–¸íŠ¸(Gradient, ë¯¸ë¶„ê°’)ë¥¼ ê³„ì‚°í•˜ê³ , ê·¸ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒë¼ë¯¸í„° ê°’ì„ ì—…ë°ì´íŠ¸. ë”°ë¼ì„œ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì„¤ì •í•˜ëŠ” ê²ƒì€ ì‹ ê²½ë§ í•™ìŠµì— í•„ìˆ˜ì ì¸ ë¶€ë¶„ìœ¼ë¡œ\nì–´ë–»ê²Œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” ëª¨ë¸ íŒŒë¼ë¯¸í„° ê°’ì„ ì°¾ì•„ë‚¼ì§€ ê²½ì •í•˜ëŠ” ë°©ë²•ì„ ì •ì˜í•˜ëŠ”ê±°ë‹¤.\n'''\n\n\n# ìµœì í™” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ AdamWë¥¼ ì‚¬ìš©, Adam(Adaptive momentum, momentumì´ ë„ì…ëœ optimizer)  ìµœì í™” ë°©ë²•ì— ê°€ì¦ì¹˜ ê°ì‡ (weight deecay)ë¥¼ ì¶”ê°€í•œ ê²ƒ\n# model.parameters()ëŠ” ìµœì í™”í•  íŒŒë¼ë¯¸í„°ë“¤(ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ë“±)ì´ë©° lr=le-5 ëŠ” í•™ìŠµë¥ (learning rate)ì´ë‹¤.\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5) # optimizer ì •ì˜ model.parameters()ëŠ” ìë™ìœ¼ë¡œ ëª¨ë¸ ë‚´ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì ¸ì˜¨ë‹¤.\ncriterion = nn.MSELoss() #loss functionìœ¼ë¡œ meab Squared Error ì‚¬ìš©, ì˜ˆì¸¡ ê°’ê³¼ ì‹¤ì œ ê°’ ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ëŠ”ë° ì‚¬ìš©","metadata":{"execution":{"iopub.status.busy":"2023-10-07T04:37:24.282319Z","iopub.execute_input":"2023-10-07T04:37:24.283412Z","iopub.status.idle":"2023-10-07T04:37:35.176579Z","shell.execute_reply.started":"2023-10-07T04:37:24.283379Z","shell.execute_reply":"2023-10-07T04:37:35.175662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nğŸ“Œ\nCreating data loader and performing sanity check (ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ì ì¸ ê²€ì¦ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ê³¼ì •)  </div>","metadata":{}},{"cell_type":"code","source":"batch_size = 16","metadata":{"execution":{"iopub.status.busy":"2023-10-07T04:37:35.178001Z","iopub.execute_input":"2023-10-07T04:37:35.178318Z","iopub.status.idle":"2023-10-07T04:37:35.182900Z","shell.execute_reply.started":"2023-10-07T04:37:35.178288Z","shell.execute_reply":"2023-10-07T04:37:35.181991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting training data into train and validation sets (í›ˆë ¨ ë°ì´í„°ë¥¼ í›ˆë ¨ ë° ê²€ì¦ ë°ì´í„°ë¡œ ë¶„í•œí•˜ê¸°)\ntrain_dataset, val_dataset = train_test_split(train_dataset, test_size=0.2, random_state=0)\n# ë°ì´í„°ë¥¼ trainìš© ë°ì´í„°ì™€ validation ë°ì´í„°ë¡œ ë‚˜ëˆˆë‹¤. train_datasetì€ 80%ë¡œ, val_datasetì€ 20%ë¡œ\n\n# Creating train loader\n# í•™ìŠµ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ê¸° ìœ„í•œ ë°ì´í„°ë¡œë” ìƒì„±. \n# train_dataset : í•™ìŠµ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  ì‚¬ìš©, ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ë•Œ ì‚¬ìš©ë˜ëŠ” ë°ì´í„°\n# batch_size : í•œë²ˆì˜ ë°°ì¹˜(batch_size)ì— í¬í•¨ë  ë°ì´í„° ìƒ˜í”Œì˜ ìˆ˜ë¥¼ ì§€ì •, ë°°ì¹˜ëŠ” ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•  ë•Œ ì‚¬ìš©\n# shuffle=True : ë°ì´í„°ë¥¼ ì„ì„ì§€ ì—¬ë¶€ë¥¼ ì§€ì • 'True'ë¡œ ì„¤ì •í•˜ë©´ ë°ì´í„°ê°€ ì—í­(epoch)ë§ˆë‹¤ ì„ì—¬ ëª¨ë¸ì˜ í›ˆë ¨ì„ ì•ˆì •í™”ì‹œí‚¤ëŠ”ë° ë„ì›€ì„ ì¤Œ, ì¦‰ í•™ìŠµ ë°ì´í„°ê°€ ì—í­ë§ˆë‹¤ ìˆœì„œê°€ ë°”ë€œ\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n\n# Creating validation loader\n# ê²€ì¦ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ê¸° ìœ„í•œ ë°ì´í„°ë¡œë” ìƒì„±. \n# val_dataset : ê²€ì¦ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  ì‚¬ìš©, ëª¨ë¸ì„ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ”ë° ì‚¬ìš©\n# batch_size : ë§ˆì°¬ê°€ì§€ë¡œ ê²€ì¦ ë°ì´í„°ë„ ë°°ì¹˜ë‹¨ìœ„ë¡œ ì²˜ë¦¬\n# shuffle=True : ê²€ì¦ ë°ì´í„°ëŠ” ë³´í†µ ìˆœì„œëŒ€ë¡œ ì‚¬ìš©í•˜ë©° ì„ì§€ ì•ŠëŠ”ê²ƒì´ ì¼ë°˜ì \nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n'''\ntorch.utils.data.DataLoaderëŠ” Pytorchì—ì„œ ì œê³µí•˜ëŠ” DataLoader\në°ì´í„° ë¡œë”ë¥¼ ì´ìš©í•˜ë©´ ë°ì´í„°ë¥¼ ì‰½ê²Œ ë°°ì¹˜ë¡œ ë¶„í• í•˜ì—¬ ëª¨ë¸ trainì´ë‚˜ validataionì— ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\nì¼ë°˜ì ìœ¼ë¡œ train dataëŠ” shuffleì„ í•˜ê³ , validattion dataëŠ” shuffleì„ ì•ˆ í•œë‹¤,\n- ì´ìœ  \ntrain dataëŠ” shuffle í•˜ëŠ” ì´ìœ ëŠ” ë°°ì¹˜ í•™ìŠµì˜ ì•ˆì •ì„± í–¥ìƒì„ ìœ„í•´ì„œë‹¤. í•™ìŠµ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ìˆœì„œëŒ€ë¡œ ëª¨ë¸ì„ í›ˆë ¨í•˜ê²Œ ë˜ëŠ”ë°\nì´ ê²½ìš° ëª¨ë¸ì€ ë°ì´í„°ì˜ ìˆœì„œì— ì˜ì¡´í•  ìˆ˜ ìˆê¸°ë•Œë¬¸ì— ëª¨ë¸ì˜ í•™ìŠµì´ ë¶ˆì•ˆì •í•´ì§ˆ ìˆ˜ ìˆë‹¤. ë°ì´í„°ë¥¼ ì„ìœ¼ë©´ ê° ì—í­(epoch)ë§ˆë‹¤ ë‹¤ë¥¸ ìˆœì„œë¡œ ë°ì´í„°ë¥¼ ì œê³µí•˜ì—¬\nëª¨ë¸ì´ ë‹¤ì–‘í•œ ë°ì´í„° íŒ¨í„´ì„ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ëŠ¥ë ¥ì´ í–¥ìƒ, ì¼ë°˜í™”(generalization) \n\nê²€ì¦ ë°ì´í„°ì˜ ìˆœì„œë¥¼ ì„ì§€ ì•ŠëŠ” ì´ìœ ëŠ” \nëª¨ë¸ í‰ê°€ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ì„œë‹¤. ê²€ì¦ ë°ì´í„°ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  íŠœë‹í•˜ëŠ”ë° ì‚¬ìš©ë˜ëŠ”ë° ìƒˆë¡œìš´ ë°ì´í„°ì— ì–¼ë§ˆë‚˜ ì˜ ì¼ë°˜í™” ë˜ëŠ”ì§€ë¥¼ í‰ê°€í•˜ëŠ” ê²ƒì´ë¼ì„œ\nê²€ì¦ ë°ì´í„°ë¥¼ ì„ìœ¼ë©´ ëª¨ë¸ì˜ í‰ê°€ê°€ ë¬´ì‘ìœ„ë¡œ ì´ë£¨ì–´ì§€ë¯€ë¡œ ì¼ê´€ëœ í‰ê°€ê°€ ì–´ë µë‹¤ ë”°ë¼ì„œ ê²€ì¦ ë°ì´í„°ëŠ” ìˆœì„œë¥¼ ìœ ì§€í•˜ì—¬ ëª¨ë¸ í‰ê°€ì˜ ì¼ê´€ì„±ì„ ìœ ì§€\n'''","metadata":{"execution":{"iopub.status.busy":"2023-10-07T04:37:35.184234Z","iopub.execute_input":"2023-10-07T04:37:35.185051Z","iopub.status.idle":"2023-10-07T04:37:35.275335Z","shell.execute_reply.started":"2023-10-07T04:37:35.185021Z","shell.execute_reply":"2023-10-07T04:37:35.274412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in train_loader:\n    print(batch)\n    print(len(batch))\n    break\n    \n'''\nì—¬ê¸°ì„œ ê°ê°ì˜ batchê°€ ëœ»í•˜ëŠ” ê²ƒ : (input_ids, attention_mask, content, wording)\nê·¸ë˜ì„œ len(batch) ì°ìœ¼ë©´ ëª¨ë‘ 4ê°€ ë‚˜ì˜¨ë‹¤.\n'''","metadata":{"execution":{"iopub.status.busy":"2023-10-07T04:37:35.276694Z","iopub.execute_input":"2023-10-07T04:37:35.277252Z","iopub.status.idle":"2023-10-07T04:37:35.296258Z","shell.execute_reply.started":"2023-10-07T04:37:35.277219Z","shell.execute_reply":"2023-10-07T04:37:35.295412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nğŸ“Œ\nTraining the model for 30 epochs    </div>","metadata":{}},{"cell_type":"code","source":"# Training loop\nmodel.train() # ëª¨ë¸ì„ í›ˆë ¨ ëª¨ë“œë¡œ ì„¤ì •. ì´ë ‡ê²Œ í•˜ë©´ ëª¨ë¸ ë‚´ë¶€ì—ì„œ ë“œë¡­ì•„ì›ƒ ë° ë°°ì¹˜ ì •ê·œí™”ì™€ ê°™ì€ í›ˆë ¨ ì¤‘ì—ë§Œ í™œì„±í™” ë˜ì–´ì•¼ í•˜ëŠ” ê¸°ëŠ¥ë“¤ì´ í™œì„±í™”\nfor epoch in range(30): # ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•œ í›ˆë ¨ì„ 30 ì—í­(epoch)ë™ì•ˆ ë°˜ë³µ\n    running_loss = 0.0 # í˜„ì¬ ì—í­ì—ì„œ ë°œìƒí•œ ëª¨ë“  ë°°ì¹˜ì˜ lossê°’ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ë³€ìˆ˜\n    \n    # í›ˆë ¨ ë°ì´í„°ë¡œë”(train_loader)ì—ì„œ ë°°ì¹˜ ë°ì´í„°ë¥¼ ë¡œë“œí•´ì„œ ê° ë°°ì¹˜ì— ëŒ€í•´ì„œ ì•„ë˜ì˜ ì½”ë“œë¥¼ ì‹¤í–‰, \n    # input_ids, attention_mask, content, wording ì€ ë°ì´í„°ì˜ ì…ë ¥ íŠ¹ì„±ë“¤ì„ ë‚˜íƒ€ëƒ„.\n    for step, (input_ids, attention_mask, content, wording) in enumerate(train_loader): \n        \n        # í•´ë‹¹ ë°°ì¹˜ì˜ ë°ì´í„°ë“¤ì„ GPUë¡œ ì´ë™\n        input_ids = input_ids.to(device) \n        attention_mask = attention_mask.to(device)\n        content = content.to(device)\n        wording = wording.to(device)\n        \n        optimizer.zero_grad() # ì´ì „ ë°°ì¹˜ì—ì„œì˜ ê¸°ìš¸ê¸° ì •ë³´ ì´ˆê¸°í™”\n        \n        # í˜„ì¬ ë°°ì¹˜ì˜ dataë¥¼ ëª¨ë¸ì— ì…ë ¥í•˜ê³  ì˜ˆì¸¡ê°’ì„ ì—†ëŠ”ë‹¤. \n        # outputsëŠ” [batch_size, 2]ê°€ ë ê²ƒì´ë‹¤.\n        outputs = model(input_ids, attention_mask) \n        \n        # output lossë¥¼ ê³„ì‚°, ëª¨ë¸ì˜ ì˜ˆì¸¡ê³¼ ì‹¤ì œ ê°’(content ë° wording)ê°„ì˜ ì°¨ì´ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.\n        loss = criterion(outputs[:, 0], content) + criterion(outputs[:, 1], wording) \n        \n        loss.backward() # ì—­ì „íŒŒ(backpropagation)ë¥¼ ìˆ˜í–‰í•˜ê³  (lossì— ëŒ€í•œ gradient ê³„ì‚°)\n        optimizer.step() # ê³„ì‚°ëœ gradientë¥¼ í†µí•´ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸\n        \n        if step % 500 == 0: # ë§¤ 500ë²ˆì§¸ ìŠ¤í…(step)ì—ì„œ í˜„ì¬ epoch step, loss ì¶œë ¥\n            print(\"Epoch {}, Step {}, Loss: {}\".format(epoch+1, step, loss.item()))\n            \n        running_loss += loss.item() # í˜„ì¬ ë°°ì¹˜ì˜ lossë¥¼ running_lossì— ëˆ„ì \n        \n    print(f\"Epoch {epoch+1} Loss: {running_loss / len(train_loader)}\") # í˜„ì¬ ì—í­ì—ì„œì˜ í‰ê·  train_losë¥¼ ì¶œë ¥.\n    \n    \n    # ë”¥ ëŸ¬ë‹ ëª¨ë¸ì˜ ê²€ì¦(validation)ë‹¨ê³„\n    model.eval() # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ ì´ë•Œ ë“œë¡­ì•„ì›ƒê³¼ ë°°ì¹˜ ì •ê·œí™”ëŠ” ë¹„í™œì„±í™”\n    with torch.no_grad(): # í•´ë‹¹ ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ëª¨ë“  ì—°ì‚°ì´ ê¸°ë¡ë˜ì§€ì•Šê³  ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì´ ë¹„í™œì„±í™”\n        val_loss = 0.0 # validation lossì„ ì €ì¥í•˜ê¸° ìœ„í•œ ë³€ìˆ˜, trainì—ì„œì™€ ë™ì¼í•˜ê²Œ ì§„í–‰, ë‹¤ë§Œ parameter ì—…ë°ì´íŠ¸ ê³¼ì •ì€ ì—†ìŒ\n        \n        # ê²€ì¦ ë°ì´í„° ë¡œë”(val_loader)ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤. (validation dataì˜ ê° ë°°ì¹˜ì— ëŒ€í•´ì„œ ì‹¤í–‰)\n        for val_step, (input_ids, attention_mask, content, wording) in enumerate(val_loader): \n            \n            # ë°ì´í„°ë“¤ì„ GPUë¡œ ì´ë™ì‹œí‚´\n            input_ids = input_ids.to(device) \n            attention_mask = attention_mask.to(device)\n            content = content.to(device)\n            wording = wording.to(device)\n            \n            val_outputs = model(input_ids, attention_mask) # ëª¨ë¸ì— ê²€ì¦ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ê³  ëª¨ë¸ì˜ ì¶œë ¥ê°’(val_output)ì„ ì–»ëŠ”ë‹¤.\n            \n            # ê²€ì¦ë°ì´í„°ì™€ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ê°„ì˜ ì°¨ì´ë¥¼ ë‚˜íƒ€ë‚´ëŠ” loss ê³„ì‚°í•˜ë©´ì„œ ê³„ì† ê²€ì¦ ì†ì‹¤ì„ ëˆ„ì í•œë‹¤.\n            val_loss += criterion(val_outputs[:, 0], content) + criterion(val_outputs[:, 1], wording) \n            \n        print(f\"Validation Loss: {val_loss / len(val_loader)}\") # ê²€ì¦ ë°ì´í„°ì…‹ì— ëŒ€í•œ í‰ê·  ê²€ì¦ ì†ì‹¤ì„ ì¶œë ¥\n    model.train() # ë‹¤ìŒ epochë¥¼ ìœ„í•´ì„œ í›ˆë ¨ëª¨ë“œë¡œ ì „í™˜, ì´ë ‡ê²Œ í•˜ë©´ ë‹¤ìŒ í›ˆë ¨ ì—í­ì—ì„œ ë‹¤ì‹œ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ê³¼ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ê°€ ê°€ëŠ¥í•´ì§","metadata":{"execution":{"iopub.status.busy":"2023-10-07T04:37:35.297709Z","iopub.execute_input":"2023-10-07T04:37:35.298234Z","iopub.status.idle":"2023-10-07T07:20:06.305608Z","shell.execute_reply.started":"2023-10-07T04:37:35.298204Z","shell.execute_reply":"2023-10-07T07:20:06.304642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nğŸ“Œ\nCreating test loader    </div>","metadata":{}},{"cell_type":"code","source":"# PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì…‹ì„ ë¡œë“œí•˜ê³  ë°ì´í„° ë¡œë”ë¥¼ ì„¤ì •í•˜ëŠ” ë¶€ë¶„\n\n# ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  ë°ì´í„°ë¡œë”ë¥¼ ì„¤ì •.\n# test_loader ì´ëŠ” ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë¯¸ë‹ˆë°°ì¹˜(mini-batch)ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” ë°ì´í„° ë¡œë” ê°ì²´ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤., ì´ë¥¼ í†µí•´ ë°ì´í„° ì…‹ì„ ë¯¸ë‹ˆë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ëª¨ë¸ì— ê³µê¸‰\n# torch.utils.data.DataLoader : PyTorchì—ì„œ ì œê³µí•˜ëŠ” ë°ì´í„° ë¡œë” í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©\n# test_dataset : ë¡œë“œí•  ë°ì´í„° ì…‹ì„ ë‚˜íƒ€ë‚¸ë‹¤.\n# batch_size=16 : ë¯¸ë‹ˆë°°ì¹˜ì˜ í¬ê¸°ë¥¼ ì„¤ì •í•˜ëŠ” ê²ƒ. ë°ì´í„°ë¥¼ 16ê°œì”© ì²˜ë¦¬í•˜ë©°, í•œë²ˆì˜ ì—­ì „íŒŒ(backpropagation)ë‹¨ê³„ë¥¼ 16ê°œì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸\n# ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ íš¨ìœ¨ì ìœ¼ë¡œ í•˜ë©´ì„œ ëª¨ë¸ í›ˆë ¨ì„ ê°€ì†í™”í•˜ëŠ”ë°ë„ì›€ì´ ë¨\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-07T07:20:06.310168Z","iopub.execute_input":"2023-10-07T07:20:06.312510Z","iopub.status.idle":"2023-10-07T07:20:06.319929Z","shell.execute_reply.started":"2023-10-07T07:20:06.312473Z","shell.execute_reply":"2023-10-07T07:20:06.319064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nğŸ“Œ\nGenerating predictions on test set (í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•œ ì˜ˆì¸¡ ìƒì„±)   </div>","metadata":{}},{"cell_type":"code","source":"# ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ì„ ìƒì„±í•˜ê³  predictions  ë¦¬ìŠ¤íŠ¸ì— ì €ì¥í•˜ëŠ” ì½”ë“œ\n\nmodel.eval() #  ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •. í‰ê°€ ëª¨ë“œì—ì„œ ëª¨ë¸ì€ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•Šê³  ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì„ í•˜ì§€ ì•ŠëŠ”ë‹¤.\npredictions = [] # ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ë¦¬ìŠ¤íŠ¸\nwith torch.no_grad(): # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì„ ë¹„í™œì„±í™”í•˜ê¸° ìœ„í•œ ë¸”ë¡\n    for input_ids, attention_mask in test_loader: # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ input_idsì™€ attention_maskë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤.\n        \n        # ë¯¸ë‹ˆë°°ì¹˜ ë‚´ì˜ ì…ë ¥ ë°ì´í„°ì™€ ë§ˆìŠ¤í¬ë¥¼ GPU ë³´ëƒ…ë‹ˆë‹¤.\n        input_ids = input_ids.to(device) \n        attention_mask = attention_mask.to(device)\n        \n        # ëª¨ë¸ì— ì…ë ¥ ë°ì´í„°ì™€ ë§ˆìŠ¤í¬ë¥¼ ì „ë‹¬í•˜ì—¬ ì˜ˆì¸¡ê°’ì„ ê³„ì‚°. outputsì—ëŠ” í•´ë‹¹ ë°°ì¹˜ì˜ ëª¨ë¸ prediction ê°’ì´ ì €ì¥ë˜ì–´ ìˆë‹¤.\n        outputs = model(input_ids, attention_mask) \n        \n        # ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì„ CPUë¡œ ì´ë™í•˜ê³ , ì´ë¥¼ predictions ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€, ëª¨ë“  ë¯¸ë‹ˆ ë°°ì¹˜ì˜ ì˜ˆì¸¡ê°’ì´ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥.\n        predictions.extend(outputs.cpu().numpy()) \n        \n        '''\n            outputs í…ì„œë¥¼ cpu()ë¡œ ì˜®ê¸°ê³ , numpy ë°°ì—´ë¡œ ë³€í™˜í•œë‹¤.\n            ê·¸ í›„ predictions ë¦¬ìŠ¤íŠ¸ì— ì´ ê°’ì„ ì¶”ê°€í•œë‹¤. cpuë¡œ ì˜¯ê¸°ëŠ” ì´ìœ ëŠ” (NumpyëŠ” CPU ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•˜ê¸°ë•Œë¬¸)\n            .numpy()ë¥¼ ì´ìš©í•´ì„œ Pytorch í…ì„œë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜í•  ë•Œ, í•´ë‹¹ í…ì„œ ê¼­ cpuì— ìˆì–´ì•¼ í•˜ê¸° ë•Œë¬¸ \n        '''","metadata":{"execution":{"iopub.status.busy":"2023-10-07T07:28:16.558507Z","iopub.execute_input":"2023-10-07T07:28:16.559214Z","iopub.status.idle":"2023-10-07T07:28:16.580249Z","shell.execute_reply.started":"2023-10-07T07:28:16.559183Z","shell.execute_reply":"2023-10-07T07:28:16.579358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nğŸ“Œ\nGenerating submission\n    </div>","metadata":{}},{"cell_type":"code","source":"submission_df = pd.DataFrame({ # ë°ì´í„° í”„ë ˆì„ì„ ìƒì„±í•˜ëŠ” ë¶€ë¶„\n    'student_id': test_data['student_id'], # ì²« ë²ˆì§¸ ì—´ 'student_id'ë¡œ ì •ì˜í•˜ê³  test_data['student_id'] ì—´ì˜ ë‚´ìš©ì„ ë„£ëŠ”ë‹¤.\n    'content': [pred[0] for pred in predictions], # ë‘ ë²ˆì§¸ ì—´ì€ 'content' ë¡œ ì •ì˜í•˜ê³  , ì´ ì—´ì—ëŠ” predictions ë¦¬ìŠ¤íŠ¸ì—ì„œ ê° ì˜ˆì¸¡ê°’('pred')ì˜ ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ ê°€ì ¸ì™€ ë„£ëŠ”ë‹¤.\n    'wording': [pred[1] for pred in predictions] # ì„¸ ë²ˆì§¸ ì—´ì€ 'wording'ìœ¼ë¡œ ì •ì˜í•˜ê³  ì´ ì—´ì—ëŠ” predictions ë¦¬ìŠ¤íŠ¸ì—ì„œ ê° ì˜ˆì¸¡ê°’ ('pred')ì˜ ë‘ ë²ˆì§¸ ìš”ì†Œë¥¼ ê°€ì ¸ì™€ ë„£ëŠ”ë‹¤.\n})\n\nsubmission_df.to_csv('submission.csv', index=False) # ìƒì„±í•œ ë°ì´í„°í”„ë ˆì„ì„ CSV íŒŒì¼ë¡œ ì €ì¥, í–‰ ë²ˆí˜¸ëŠ” í¬í•¨ë˜ì§€ ì•Šë„ë¡ index=False ë¡œ ì„¤ì •","metadata":{"execution":{"iopub.status.busy":"2023-10-07T07:28:46.681964Z","iopub.execute_input":"2023-10-07T07:28:46.682301Z","iopub.status.idle":"2023-10-07T07:28:46.690843Z","shell.execute_reply.started":"2023-10-07T07:28:46.682274Z","shell.execute_reply":"2023-10-07T07:28:46.689810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2023-10-07T07:28:56.614446Z","iopub.execute_input":"2023-10-07T07:28:56.614873Z","iopub.status.idle":"2023-10-07T07:28:56.624105Z","shell.execute_reply.started":"2023-10-07T07:28:56.614837Z","shell.execute_reply":"2023-10-07T07:28:56.623161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}